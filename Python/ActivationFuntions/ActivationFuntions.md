# Activation Functions

## Why do we neeed Activation Functions :

If we dont't add Non linearities by using activation functions then our output will be only a linear funtion of input, thus making it impossible to learn complex features.It will only learn lones or planes. Thus Univerrsal approximation theorem will not hold any more in this case.

## Sigmoid :

![Sigmoid](https://miro.medium.com/max/4384/1*6A3A_rt4YmumHusvTvVTxw.png)

![Sigmoid](https://miro.medium.com/max/1298/1*cZXcFBwhVb54D0l1-ZAZ7Q.png)





